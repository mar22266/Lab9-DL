{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0489670",
   "metadata": {},
   "source": [
    "## Integrantes \n",
    "- Andre Marroquin\n",
    "- Joaquin Puente\n",
    "- Sergio Orellana\n",
    "- Nelson Garcia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284213fa",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09582420",
   "metadata": {},
   "source": [
    "## Arquitectura LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768dba8f",
   "metadata": {},
   "source": [
    "### imports, semillas y utilidades comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc945fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports principales\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# asegurar reproducibilidad básica\n",
    "def seed_everything(seed: int = 42) -> None:\n",
    "    import random\n",
    "    import numpy as np\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# elegir dispositivo\n",
    "def get_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e24c96b",
   "metadata": {},
   "source": [
    "### métricas accuracy y macro-f1 y bucles de entrenamiento/evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular accuracy \n",
    "def accuracy_from_logits(logits: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "    preds = logits.argmax(dim=1)\n",
    "    correct = (preds == targets).sum().item()\n",
    "    total = targets.numel()\n",
    "    return correct / total\n",
    "\n",
    "# construir matriz de confusión\n",
    "def confusion_matrix(num_classes: int, preds: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    cm = torch.zeros((num_classes, num_classes), dtype=torch.long)\n",
    "    for t, p in zip(targets.view(-1), preds.view(-1)):\n",
    "        cm[t.long(), p.long()] += 1\n",
    "    return cm\n",
    "\n",
    "# calcular macro-f1 desde matriz de confusión\n",
    "def macro_f1_from_confusion(cm: torch.Tensor) -> float:\n",
    "    cm = cm.to(torch.float32)\n",
    "    tp = torch.diag(cm)\n",
    "    fp = cm.sum(dim=0) - tp\n",
    "    fn = cm.sum(dim=1) - tp\n",
    "\n",
    "    precision = tp / torch.clamp(tp + fp, min=1.0)\n",
    "    recall = tp / torch.clamp(tp + fn, min=1.0)\n",
    "    f1 = 2.0 * precision * recall / torch.clamp(precision + recall, min=1e-12)\n",
    "    return f1.mean().item()\n",
    "\n",
    "# ciclo de entrenamiento por época\n",
    "def train_one_epoch(model: nn.Module,\n",
    "                    loader: DataLoader,\n",
    "                    criterion: nn.Module,\n",
    "                    optimizer: optim.Optimizer,\n",
    "                    device: torch.device,\n",
    "                    log_every: int = 100) -> Dict[str, float]:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    count = 0\n",
    "\n",
    "    t0 = time.time()\n",
    "    for step, (x, y) in enumerate(loader, 1):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_acc = accuracy_from_logits(logits, y)\n",
    "        running_loss += loss.item()\n",
    "        running_acc += batch_acc\n",
    "        count += 1\n",
    "\n",
    "        if step % log_every == 0:\n",
    "            print(f\"step {step:04d} | loss {running_loss / count:.4f} | acc {running_acc / count:.4f}\")\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    return {\n",
    "        \"train_loss\": running_loss / max(count, 1),\n",
    "        \"train_acc\":  running_acc / max(count, 1),\n",
    "        \"train_time_s\": dt\n",
    "    }\n",
    "\n",
    "# evaluación completa \n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module,\n",
    "             loader: DataLoader,\n",
    "             criterion: nn.Module,\n",
    "             device: torch.device,\n",
    "             num_classes: int) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    count = 0\n",
    "    cm = torch.zeros((num_classes, num_classes), dtype=torch.long)\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += accuracy_from_logits(logits, y)\n",
    "        count += 1\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        cm += confusion_matrix(num_classes, preds.cpu(), y.cpu())\n",
    "\n",
    "    macro_f1 = macro_f1_from_confusion(cm)\n",
    "    return {\n",
    "        \"val_loss\": total_loss / max(count, 1),\n",
    "        \"val_acc\":  total_acc / max(count, 1),\n",
    "        \"val_macro_f1\": macro_f1\n",
    "    }\n",
    "\n",
    "# bucle de entrenamiento de varias épocas con mejor modelo por accuracy\n",
    "def fit(model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        criterion: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler,\n",
    "        device: torch.device,\n",
    "        num_classes: int,\n",
    "        epochs: int = 5,\n",
    "        name: str = \"model\") -> Tuple[nn.Module, Dict[str, float]]:\n",
    "    best_state = None\n",
    "    best_acc = -1.0\n",
    "    history = {}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\n==> {name} | epoch {epoch}/{epochs}\")\n",
    "        train_stats = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_stats = evaluate(model, val_loader, criterion, device, num_classes)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"train  | loss {train_stats['train_loss']:.4f} acc {train_stats['train_acc']:.4f} time {train_stats['train_time_s']:.1f}s\")\n",
    "        print(f\"valid  | loss {val_stats['val_loss']:.4f} acc {val_stats['val_acc']:.4f} macro_f1 {val_stats['val_macro_f1']:.4f}\")\n",
    "\n",
    "        # actualizar mejor\n",
    "        if val_stats[\"val_acc\"] > best_acc:\n",
    "            best_acc = val_stats[\"val_acc\"]\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "        history[epoch] = {**train_stats, **val_stats}\n",
    "\n",
    "    # cargar mejor estado antes de devolver\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    print(f\"\\n>> best val acc: {best_acc:.4f}\")\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9793bf",
   "metadata": {},
   "source": [
    "### datos para lenet-5 (mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01fe9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 14.9MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 436kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.75MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.80MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforms para mnist \n",
    "mnist_mean, mnist_std = (0.1307,), (0.3081,)\n",
    "\n",
    "train_tf_mnist = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mnist_mean, mnist_std),\n",
    "])\n",
    "\n",
    "test_tf_mnist = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mnist_mean, mnist_std),\n",
    "])\n",
    "\n",
    "# cargar datasets y dataloaders\n",
    "data_root = \"./data\"\n",
    "\n",
    "train_mnist = datasets.MNIST(root=data_root, train=True, download=True, transform=train_tf_mnist)\n",
    "test_mnist  = datasets.MNIST(root=data_root, train=False, download=True, transform=test_tf_mnist)\n",
    "\n",
    "batch_size_mnist = 128\n",
    "num_workers = min(4, os.cpu_count() or 0)\n",
    "\n",
    "train_loader_mnist = DataLoader(train_mnist, batch_size=batch_size_mnist, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader_mnist   = DataLoader(test_mnist,  batch_size=batch_size_mnist, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "len(train_mnist), len(test_mnist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd121eb",
   "metadata": {},
   "source": [
    "### modelo lenet-5 (implementación clásica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cc084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementación clásica de LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# instanciar lenet-5\n",
    "lenet5 = LeNet5(num_classes=10).to(device)\n",
    "\n",
    "# definir criterio y optimizador\n",
    "criterion_mnist = nn.CrossEntropyLoss()\n",
    "optimizer_mnist = optim.SGD(lenet5.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler_mnist = optim.lr_scheduler.StepLR(optimizer_mnist, step_size=5, gamma=0.5)\n",
    "\n",
    "lenet5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d2e0a",
   "metadata": {},
   "source": [
    "### entrenamiento y evaluación de lenet-5 (mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207dd613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> lenet5-mnist | epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0100 | loss 1.5063 | acc 0.6021\n",
      "step 0200 | loss 0.9771 | acc 0.7418\n",
      "step 0300 | loss 0.7628 | acc 0.7953\n",
      "step 0400 | loss 0.6385 | acc 0.8272\n",
      "train  | loss 0.5815 acc 0.8415 time 29.4s\n",
      "valid  | loss 0.2084 acc 0.9386 macro_f1 0.9380\n",
      "\n",
      "==> lenet5-mnist | epoch 2/5\n",
      "step 0100 | loss 0.1998 | acc 0.9414\n",
      "step 0200 | loss 0.1911 | acc 0.9446\n",
      "step 0300 | loss 0.1803 | acc 0.9481\n",
      "step 0400 | loss 0.1701 | acc 0.9507\n",
      "train  | loss 0.1616 acc 0.9530 time 28.2s\n",
      "valid  | loss 0.1109 acc 0.9687 macro_f1 0.9680\n",
      "\n",
      "==> lenet5-mnist | epoch 3/5\n",
      "step 0100 | loss 0.1056 | acc 0.9698\n",
      "step 0200 | loss 0.1060 | acc 0.9699\n",
      "step 0300 | loss 0.1020 | acc 0.9708\n",
      "step 0400 | loss 0.0994 | acc 0.9715\n",
      "train  | loss 0.0970 acc 0.9721 time 22.0s\n",
      "valid  | loss 0.0712 acc 0.9775 macro_f1 0.9771\n",
      "\n",
      "==> lenet5-mnist | epoch 4/5\n",
      "step 0100 | loss 0.0750 | acc 0.9788\n",
      "step 0200 | loss 0.0732 | acc 0.9791\n",
      "step 0300 | loss 0.0733 | acc 0.9790\n",
      "step 0400 | loss 0.0731 | acc 0.9791\n",
      "train  | loss 0.0720 acc 0.9792 time 22.6s\n",
      "valid  | loss 0.0618 acc 0.9806 macro_f1 0.9802\n",
      "\n",
      "==> lenet5-mnist | epoch 5/5\n",
      "step 0100 | loss 0.0593 | acc 0.9830\n",
      "step 0200 | loss 0.0600 | acc 0.9825\n",
      "step 0300 | loss 0.0600 | acc 0.9825\n",
      "step 0400 | loss 0.0592 | acc 0.9827\n",
      "train  | loss 0.0595 acc 0.9827 time 30.4s\n",
      "valid  | loss 0.0493 acc 0.9858 macro_f1 0.9856\n",
      "\n",
      ">> best val acc: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.049348667984580784,\n",
       " 'val_acc': 0.9857594936708861,\n",
       " 'val_macro_f1': 0.9855717420578003}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entrenar lenet-5 \n",
    "epochs_mnist = 5  \n",
    "\n",
    "lenet5, history_mnist = fit(\n",
    "    model=lenet5,\n",
    "    train_loader=train_loader_mnist,\n",
    "    val_loader=val_loader_mnist,\n",
    "    criterion=criterion_mnist,\n",
    "    optimizer=optimizer_mnist,\n",
    "    scheduler=scheduler_mnist,\n",
    "    device=device,\n",
    "    num_classes=10,\n",
    "    epochs=epochs_mnist,\n",
    "    name=\"lenet5-mnist\"\n",
    ")\n",
    "\n",
    "# evaluación final en test\n",
    "final_stats_mnist = evaluate(lenet5, val_loader_mnist, criterion_mnist, device, num_classes=10)\n",
    "final_stats_mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e749ba",
   "metadata": {},
   "source": [
    "### impresión de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dd2f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== resultados finales ==\n",
      "lenet-5 (mnist)  -> acc: 0.9858 | macro-f1: 0.9856\n"
     ]
    }
   ],
   "source": [
    "print(\"== resultados finales ==\")\n",
    "print(f\"lenet-5 (mnist)  -> acc: {final_stats_mnist['val_acc']:.4f} | macro-f1: {final_stats_mnist['val_macro_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0e258",
   "metadata": {},
   "source": [
    "### Métrica de desempeño (definición y justificación)\n",
    "\n",
    "Métrica elegida para LeNet-5 con el dataset MNIST: accuracy como métrica principal.  \n",
    "La razón es que MNIST tiene diez clases balanceadas y el objetivo es identificar correctamente el dígito.  \n",
    "La accuracy muestra de forma directa qué proporción de predicciones fue correcta y es muy fácil de interpretar.  \n",
    "También se usa la métrica macro F1 como apoyo, ya que muestra el equilibrio entre clases y ayuda a tener una visión más completa, aunque en este caso el dataset está bien balanceado.\n",
    "\n",
    "---\n",
    "\n",
    "### Respuestas teóricas\n",
    "\n",
    "a. Diferencia principal entre ambas arquitecturas  \n",
    "LeNet-5 es una red pequeña y de las primeras en su tipo. Tiene pocas capas, usa funciones de activación suaves y fue pensada para imágenes en blanco y negro de baja resolución, como las de 32 por 32 píxeles.  \n",
    "AlexNet, en cambio, es más grande y profunda. Utiliza activaciones más rápidas, técnicas de regularización como dropout y trabaja con imágenes a color de alta resolución.  \n",
    "En resumen, AlexNet tiene mucha más capacidad, maneja imágenes más grandes y usa técnicas más modernas para mejorar el rendimiento.\n",
    "\n",
    "b. ¿Podría usarse LeNet-5 para el problema de AlexNet? ¿Y viceversa?  \n",
    "LeNet-5 podría usarse en problemas más complejos si se adapta, por ejemplo, agregando más canales de color o ampliando la entrada, pero su capacidad no sería suficiente para tareas tan grandes y diversas como las que resuelve AlexNet.  \n",
    "AlexNet, por otro lado, sí podría entrenarse con MNIST, pero sería demasiado grande para un problema tan simple. En ese caso podría sobreajustar o desperdiciar recursos sin aportar beneficios reales frente a modelos más ligeros como LeNet-5.\n",
    "\n",
    "c. Aspectos más interesantes de cada arquitectura  \n",
    "En LeNet-5 destaca su simplicidad y eficiencia. A pesar de tener pocas capas, logra un gran desempeño en el reconocimiento de dígitos escritos a mano y es muy útil para aprender los fundamentos de las redes convolucionales.  \n",
    "En AlexNet, lo más interesante es cómo combina varias ideas que marcaron un cambio importante en la visión por computadora: el uso de activaciones rápidas, regularización y una estructura más profunda, lo que permitió alcanzar resultados sobresalientes en tareas a gran escala.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
